{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "6hq_nOrnU40d",
        "outputId": "da911a93-742d-402c-e623-341654b7e0eb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting rdkit\n",
            "  Downloading rdkit-2024.9.5-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (4.0 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from rdkit) (1.26.4)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from rdkit) (11.1.0)\n",
            "Downloading rdkit-2024.9.5-cp311-cp311-manylinux_2_28_x86_64.whl (34.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m34.3/34.3 MB\u001b[0m \u001b[31m62.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: rdkit\n",
            "Successfully installed rdkit-2024.9.5\n"
          ]
        }
      ],
      "source": [
        "!pip install rdkit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SKx0VrnKUDQU",
        "outputId": "f5254bf2-bc6b-43df-9de9-76ed326cc5c8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "前1000行数据处理完成，结果已保存至 enhanced_molecules_top1000.csv\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from rdkit import Chem\n",
        "from rdkit.Chem import AllChem\n",
        "\n",
        "def generate_smiles_variants(smiles):\n",
        "    try:\n",
        "        mol = Chem.MolFromSmiles(smiles)\n",
        "        if mol is None:\n",
        "            raise ValueError(\"Invalid SMILES\")\n",
        "\n",
        "        variants = {\n",
        "            'Canonical_SMILES': Chem.MolToSmiles(mol, canonical=True),\n",
        "            'Random_SMILES_1': Chem.MolToSmiles(mol, doRandom=True, canonical=False),\n",
        "            'Random_SMILES_2': Chem.MolToSmiles(mol, doRandom=True, canonical=False),\n",
        "            'NonIsomeric_SMILES': Chem.MolToSmiles(mol, isomericSmiles=False),\n",
        "            'Kekule_SMILES': Chem.MolToSmiles(mol, kekuleSmiles=True),\n",
        "            'SMILES_with_Hs': Chem.MolToSmiles(mol, allHsExplicit=True),\n",
        "            'Branchless_SMILES': Chem.MolToSmiles(mol, canonical=False, doRandom=False).replace(\"(\", \"\").replace(\")\", \"\")\n",
        "        }\n",
        "\n",
        "        AllChem.Compute2DCoords(mol)\n",
        "        variants['SMILES_2D'] = Chem.MolToSmiles(mol)\n",
        "\n",
        "        return variants\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing {smiles}: {str(e)}\")\n",
        "        return {key: None for key in [\n",
        "            'Canonical_SMILES',\n",
        "            'Random_SMILES_1',\n",
        "            'Random_SMILES_2',\n",
        "            'NonIsomeric_SMILES',\n",
        "            'Kekule_SMILES',\n",
        "            'SMILES_with_Hs',\n",
        "            'Branchless_SMILES',\n",
        "            'SMILES_2D'\n",
        "        ]}\n",
        "\n",
        "input_file = \"/content/250k_rndm_zinc_drugs_clean_3.csv\"\n",
        "output_file = \"enhanced_molecules_top1000.csv\"\n",
        "\n",
        "df = pd.read_csv(input_file).head(1000)\n",
        "\n",
        "variants_df = df[\"smiles\"].apply(lambda x: pd.Series(generate_smiles_variants(x)))\n",
        "\n",
        "enhanced_df = pd.concat([df, variants_df], axis=1)\n",
        "enhanced_df.to_csv(output_file, index=False)\n",
        "print(f\"Processed data is saved at {output_file}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V4Lw1b8Wapre",
        "outputId": "acad0ba1-7a9c-4e2a-f383-787bae7fdb8f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai in /usr/local/lib/python3.11/dist-packages (1.61.1)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.8.2)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from openai) (2.10.6)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.11/dist-packages (from openai) (4.12.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (2.27.2)\n",
            "Collecting python-dotenv\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
            "Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Installing collected packages: python-dotenv\n",
            "Successfully installed python-dotenv-1.0.1\n"
          ]
        }
      ],
      "source": [
        "!pip install openai\n",
        "!pip install python-dotenv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zZvC2ek5ed_d",
        "outputId": "87f3b801-1b74-464e-a5c0-0bf34afcc868"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found existing installation: openai 1.61.1\n",
            "Uninstalling openai-1.61.1:\n",
            "  Successfully uninstalled openai-1.61.1\n"
          ]
        }
      ],
      "source": [
        "\n",
        "!pip uninstall openai -y\n",
        "!pip install openai>=1.0.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0YDTI_teeqF4"
      },
      "outputs": [],
      "source": [
        "!pip install openai>=1.0.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7WFAVu6gaoR8",
        "outputId": "69b4a7c3-2d88-4b05-b009-058e47d960d6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "处理分子: 100%|██████████| 500/500 [2:18:21<00:00, 16.60s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== 最终分析结果 ===\n",
            "          SMILES类型   性质   MAE  RMSE      R²  p值  样本量\n",
            "            smiles logP 0.843 1.128   0.365 0.0  500\n",
            "            smiles  qed 0.199 0.226  -1.615 0.0  500\n",
            "            smiles  SAS 2.261 2.493  -9.188 0.0  500\n",
            "  Canonical_SMILES logP 0.840 1.123   0.370 0.0  500\n",
            "  Canonical_SMILES  qed 0.199 0.226  -1.613 0.0  500\n",
            "  Canonical_SMILES  SAS 2.189 2.413  -8.545 0.0  500\n",
            "   Random_SMILES_1 logP 0.816 1.080   0.418 0.0  500\n",
            "   Random_SMILES_1  qed 0.190 0.221  -1.498 0.0  500\n",
            "   Random_SMILES_1  SAS 2.366 2.583  -9.941 0.0  500\n",
            "   Random_SMILES_2 logP 0.836 1.105   0.390 0.0  500\n",
            "   Random_SMILES_2  qed 0.196 0.226  -1.620 0.0  500\n",
            "   Random_SMILES_2  SAS 2.389 2.605 -10.129 0.0  500\n",
            "NonIsomeric_SMILES logP 0.889 1.184   0.300 0.0  500\n",
            "NonIsomeric_SMILES  qed 0.220 0.248  -2.166 0.0  500\n",
            "NonIsomeric_SMILES  SAS 2.156 2.393  -8.389 0.0  500\n",
            "     Kekule_SMILES logP 0.787 1.055   0.444 0.0  500\n",
            "     Kekule_SMILES  qed 0.192 0.219  -1.469 0.0  500\n",
            "     Kekule_SMILES  SAS 2.266 2.502  -9.263 0.0  500\n",
            "    SMILES_with_Hs logP 0.958 1.278   0.185 0.0  500\n",
            "    SMILES_with_Hs  qed 0.197 0.227  -1.642 0.0  500\n",
            "    SMILES_with_Hs  SAS 2.581 2.785 -11.718 0.0  500\n",
            " Branchless_SMILES logP 1.026 1.330   0.117 0.0  500\n",
            " Branchless_SMILES  qed 0.228 0.258  -2.419 0.0  500\n",
            " Branchless_SMILES  SAS 2.828 3.021 -13.961 0.0  500\n",
            "         SMILES_2D logP 0.837 1.134   0.358 0.0  500\n",
            "         SMILES_2D  qed 0.195 0.223  -1.555 0.0  500\n",
            "         SMILES_2D  SAS 2.272 2.488  -9.147 0.0  500\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import time\n",
        "import json\n",
        "import logging\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from scipy import stats\n",
        "from tqdm import tqdm\n",
        "from openai import OpenAI\n",
        "from dotenv import load_dotenv\n",
        "from typing import Dict, Optional\n",
        "\n",
        "\n",
        "logging.basicConfig(\n",
        "    level=logging.INFO,\n",
        "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
        "    handlers=[\n",
        "        logging.FileHandler(\"api_experiment.log\"),\n",
        "        logging.StreamHandler()\n",
        "    ]\n",
        ")\n",
        "\n",
        "load_dotenv()\n",
        "client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
        "\n",
        "CONFIG = {\n",
        "    \"input_file\": \"enhanced_molecules_top1000.csv\",\n",
        "    \"output_file\": \"api_predictions.csv\",\n",
        "    \"smiles_columns\": [\n",
        "        'smiles',\n",
        "        'Canonical_SMILES',\n",
        "        'Random_SMILES_1',\n",
        "        'Random_SMILES_2',\n",
        "        'NonIsomeric_SMILES',\n",
        "        'Kekule_SMILES',\n",
        "        'SMILES_with_Hs',\n",
        "        'Branchless_SMILES',\n",
        "        'SMILES_2D'\n",
        "    ],\n",
        "    \"properties\": ['logP', 'qed', 'SAS'],\n",
        "    \"model\": \"gpt-4-turbo\",\n",
        "    \"max_retries\": 3,\n",
        "    \"request_timeout\": 30,\n",
        "    \"temperature\": 0.3,\n",
        "    \"batch_size\": 10\n",
        "}\n",
        "\n",
        "def build_prompt(smiles: str) -> str:\n",
        "    return f\"\"\"As a computational chemistry assistant, predict the following properties for the molecule: {smiles}\n",
        "\n",
        "Return ONLY a properly formatted JSON object with the following structure:\n",
        "{{\n",
        "    \"logP\": <float_value>,    // Predicted octanol-water partition coefficient (3 decimal places)\n",
        "    \"qed\": <float_value>,     // Quantitative Estimate of Drug-likeness (0-1, 3 decimals)\n",
        "    \"SAS\": <float_value>      // Synthetic Accessibility Score (1-10, 3 decimals)\n",
        "}}\n",
        "\n",
        "Important:\n",
        "1. Do not include any explanatory text\n",
        "2. Ensure proper JSON syntax\n",
        "3. Maintain exact key names\n",
        "4. Values must be numeric\"\"\"\n",
        "\n",
        "def parse_response(content: str) -> Optional[Dict]:\n",
        "    try:\n",
        "\n",
        "        start = content.find('{')\n",
        "        end = content.rfind('}') + 1\n",
        "        json_str = content[start:end]\n",
        "\n",
        "        json_str = json_str.replace(\"'\", '\"')\n",
        "        json_str = json_str.replace(\"True\", \"true\").replace(\"False\", \"false\")\n",
        "\n",
        "        parsed = json.loads(json_str)\n",
        "\n",
        "        required_keys = set(CONFIG[\"properties\"])\n",
        "        if not all(key in parsed for key in required_keys):\n",
        "            raise ValueError(\"Missing required keys\")\n",
        "\n",
        "        for k, v in parsed.items():\n",
        "            if not isinstance(v, (int, float)):\n",
        "                raise ValueError(f\"Invalid type for {k}: {type(v)}\")\n",
        "\n",
        "        return parsed\n",
        "\n",
        "    except (json.JSONDecodeError, ValueError, TypeError, KeyError) as e:\n",
        "        logging.error(f\"error: {str(e)}\")\n",
        "        logging.debug(f\"bug: {content}\")\n",
        "        return None\n",
        "\n",
        "def query_api(smiles: str) -> Optional[Dict]:\n",
        "    for attempt in range(CONFIG[\"max_retries\"] + 1):\n",
        "        try:\n",
        "            response = client.chat.completions.create(\n",
        "                model=CONFIG[\"model\"],\n",
        "                messages=[\n",
        "                    {\"role\": \"system\", \"content\": \"You are a helper that only returns valid JSON, and a drug expert\"},\n",
        "                    {\"role\": \"user\", \"content\": build_prompt(smiles)}\n",
        "                ],\n",
        "                temperature=CONFIG[\"temperature\"],\n",
        "                timeout=CONFIG[\"request_timeout\"]\n",
        "            )\n",
        "\n",
        "            if not response.choices:\n",
        "                raise ValueError(\"Empty API response\")\n",
        "\n",
        "            content = response.choices[0].message.content\n",
        "            parsed = parse_response(content)\n",
        "\n",
        "            if parsed:\n",
        "                return parsed\n",
        "\n",
        "        except Exception as e:\n",
        "            if attempt < CONFIG[\"max_retries\"]:\n",
        "                sleep_time = 2 ** attempt + np.random.uniform(0, 1)\n",
        "                logging.warning(f\"Try {attempt+1}/{CONFIG['max_retries']} 失败: {str(e)} - 等待 {sleep_time:.1f}s\")\n",
        "                time.sleep(sleep_time)\n",
        "            else:\n",
        "                logging.error(f\"all retry fail: {smiles}\")\n",
        "                return None\n",
        "\n",
        "def process_batch(df: pd.DataFrame) -> pd.DataFrame:\n",
        "    results = pd.DataFrame(\n",
        "        index=df.index,\n",
        "        columns=pd.MultiIndex.from_product(\n",
        "            [CONFIG[\"smiles_columns\"], CONFIG[\"properties\"]],\n",
        "            names=['SMILES Type', 'Properties']\n",
        "        )\n",
        "    )\n",
        "\n",
        "    for idx, row in tqdm(df.iterrows(), total=len(df), desc=\"Handle Molecules\"):\n",
        "        for col in CONFIG[\"smiles_columns\"]:\n",
        "            smiles = row[col]\n",
        "\n",
        "            if pd.isna(smiles):\n",
        "                logging.warning(f\"Column {idx} Row {col} contains empty value\")\n",
        "                continue\n",
        "\n",
        "            predictions = query_api(smiles)\n",
        "\n",
        "            for prop in CONFIG[\"properties\"]:\n",
        "                results.loc[idx, (col, prop)] = predictions.get(prop, np.nan) if predictions else np.nan\n",
        "\n",
        "    return results\n",
        "\n",
        "def analyze_results(predictions: pd.DataFrame, true_values: pd.DataFrame) -> pd.DataFrame:\n",
        "    analysis = []\n",
        "\n",
        "    for col in CONFIG[\"smiles_columns\"]:\n",
        "        for prop in CONFIG[\"properties\"]:\n",
        "            pred_col = (col, prop)\n",
        "\n",
        "            temp_df = pd.DataFrame({\n",
        "                f'{prop}_true': true_values[prop],\n",
        "                f'{prop}_pred': predictions[pred_col]\n",
        "            })\n",
        "\n",
        "            temp_df = temp_df.dropna()\n",
        "\n",
        "            if len(temp_df) < 5:\n",
        "                continue\n",
        "\n",
        "            mae = np.mean(np.abs(temp_df[f'{prop}_pred'] - temp_df[f'{prop}_true']))\n",
        "            rmse = np.sqrt(np.mean((temp_df[f'{prop}_pred'] - temp_df[f'{prop}_true'])**2))\n",
        "            r2 = 1 - (np.sum((temp_df[f'{prop}_pred'] - temp_df[f'{prop}_true'])**2)\n",
        "                     / np.sum((temp_df[f'{prop}_true'] - np.mean(temp_df[f'{prop}_true']))**2))\n",
        "\n",
        "            _, p_value = stats.ttest_rel(temp_df[f'{prop}_pred'], temp_df[f'{prop}_true'])\n",
        "\n",
        "            analysis.append({\n",
        "                'SMILES Type': col,\n",
        "                '{Properties}': prop,\n",
        "                'MAE': mae,\n",
        "                'RMSE': rmse,\n",
        "                'R²': r2,\n",
        "                'p value': p_value,\n",
        "                '#samples': len(temp_df)\n",
        "            })\n",
        "\n",
        "    return pd.DataFrame(analysis)\n",
        "def main():\n",
        "    try:\n",
        "        df = pd.read_csv(CONFIG[\"input_file\"]).head(500)\n",
        "        logging.info(f\"process {len(df)} lines data\")\n",
        "\n",
        "        predictions = process_batch(df)\n",
        "\n",
        "        final_df = pd.concat([df, predictions], axis=1)\n",
        "        final_df.to_csv(CONFIG[\"output_file\"], index=False)\n",
        "        logging.info(f\"The outcome is saved at {CONFIG['output_file']}\")\n",
        "\n",
        "        # 分析结果\n",
        "        analysis_df = analyze_results(predictions, df[CONFIG[\"properties\"]])\n",
        "        print(\"\\Ultimate Result\")\n",
        "        print(analysis_df.round(3).to_string(index=False))\n",
        "\n",
        "    except Exception as e:\n",
        "        logging.critical(f\"The main process fails: {str(e)}\", exc_info=True)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}